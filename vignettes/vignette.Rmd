---
title: "tan: A differential analysis pipeline for ChIP-seq data."
author: |
        | Duy Nguyen and S&#252;nd&#252;z Kele&#351;
        | Department of Statistics, University of Wisconsin-Madison
date: "`r Sys.Date()`"
output: 
    BiocStyle::html_document2
bibliography: biblio.bib    
biblio-style: plain
vignette: >
    %\VignetteIndexEntry{Vignette Title}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}  
---

<meta http-equiv="content-type" content="text/html;charset=utf-8" />

```{r style, echo = FALSE, results = 'asis'}

    library(BiocStyle)
    markdown(css.files = c('custom.css'))

```

```{r extraload, include = FALSE, echo = FALSE, eval = TRUE}
    library(tan)
    library(knitr)
    library(ggplot2)
    opts_chunk$set(fig.align = "center")

```    
# Introduction to the tan package

We present a brief overview of the [tan](https://github.com/duydnguyen/tan/) package. This package provides a framework for identifying differentially enriched (DE) regions from ChIP-seq data. In this vignette, we utilized the data from a ChIP-seq experiment investigating H3K27me3 to illustrate our pipeline. To load the required packages, we use:

```{r load,include=TRUE,echo=TRUE,eval=FALSE}
    library(tan)
    library(tanExample)

```

For a typical workflow, [tan](https://github.com/duydnguyen/tan/) takes a set of genomic regions (or peaks) and their aligned reads from ChIP-seq experements. Its goal is to predict the DE regions between two or multiple conditions. Specifically, the pipeline performs the following steps:

# Inputs

## A set of pre-define regions for DE pipeline
For its first input, [tan](https://github.com/duydnguyen/tan/) takes a set of genemic regions in `BED` format as candidates to perform differential analysis. If such candidate regions are unavailable, we suggest using `r Biocpkg("mosaics")` to obtain these regions.

## Read coverage data 
After a set of candidate regions is available, [tan](https://github.com/duydnguyen/tan/) also takes read coverages as its additional inputs. There are several ways to load count data from bam files and convert them into counts. Other Bioconductor packages with similar aims are `r Biocpkg("bamsignals")` or [Segvis](https://github.com/keleslab/Segvis). Here, illustrate a way of obtain these coverage data via [tan](https://github.com/duydnguyen/tan/). A typical workflow of obtaining reads requires to firstly load all reads in R, secondly process them and lastly convert them into counts. [tan](https://github.com/duydnguyen/tan/) package was efficiently implemented to merge these steps into one single function `bamCoverage()`. 

### Loading toy data

 [tan](https://github.com/duydnguyen/tan/) accepts bam file to generate read coverages. First, we load the required packages (which are all required for installing `tan`).

```{r loadSegvis_show, include = TRUE, echo = TRUE, eval = FALSE}
    library(GenomicRanges)
    library(GenomicAlignments)
    library(data.table)
    
```   

```{r loadSegvis_noshow, include = FALSE, echo = FALSE, eval = TRUE}
    library(GenomicRanges)
    library(GenomicAlignments)
    library(data.table)
    
```   
For demonstration, we used the H3K27me3's region of BZW2's gene body whose genomic coordinates are stored in BZW2.bed. In the following, we will use sorted and index bam files to load reads. The bam files need to be sorted and indexed. Note that `tan` require the bam index to be named like bam file with ".bai" suffix.  

```{r extractBam, include=TRUE, echo=TRUE, eval=TRUE}
files = list.files(system.file("extdata/bzw2",
        package = "tanExample"),full.names = TRUE)
basename(files[c(1,3,6,9,12)])
bam_files <- files[c(3,6, 9, 12)]
bed_files <- files[1]
# checking if there is an index 
file.exists(gsub(".bam$", ".bam.bai", files[c(1,3,6,9,12)]))
```

Here we show the most basic steps for a differential analysis. These code chunks assume that you have a table of sample information called `coldata`. This table includes: `SampleID`, `Condition`, and `bam_files`, which could be generated by the following codes:

```{r colData, include=TRUE, echo=TRUE, eval=TRUE}
sample.ids <- c('rep1_4HT-', 'rep1_4HT+', 'rep2_4HT-', 'rep2_4HT+')
condition <- factor(c(rep(c('4HT-', '4HT+'), 2 )))
coldata <- data.frame('SampleID' = sample.ids, 'Condition' = condition, 'bam_files' = bam_files)
```

We then set up the following parameters 

```{r params, include=TRUE, echo=TRUE, eval=TRUE}
# width of bins to count reads mapping to regions
binsize <- 150
# smooth parameter
sm <- 1 
mc_cores <- 3
bed_content <- read.table(file = files[1], stringsAsFactors = FALSE)
gr <- GRanges(seqnames = bed_content[, 1],
              ranges = IRanges(bed_content[,2], bed_content[,3]), 
              strand = "*")
chromosomes <- c("chr7")
gr
```

The `binsize` parameter indicated how reads are counted. A value of 1 correponds to single base pairs. Very often it is better to count reads mapping to bins. Bins are small partitions of fixed size tiling a larger region. `bamCoverage()` introduces the `binsize` option to implement this.

Next, let's count how many reads map to the regions given in the bed file. Using the `bamCoverage()`, this is straighforward. 

```{r bamCoverage, include=TRUE, echo=TRUE, eval=TRUE}
coverage <- tan::bamCoverage(colData = coldata, bed_files = bed_files,
                         mc_cores = mc_cores, sm = sm, binsize = binsize)

class(coverage)
length(coverage)
```

`bamCoverage()` returns a coverage list whose length equals to the number of regions in the given bed file. Each element of coverage list is a matrix storing values of reads. For each conditions, average profiles  for a given peak (e.g. peak 3) can be plotted like this

```{r bamCoverage_plot, include=TRUE, echo=TRUE, eval=TRUE}
peak.id <- 1
tan::plotCoverage(coverage, peak_id = peak.id,title = toString(gr[peak.id]))
```

Additionally, `plotCoverage` can generate enrichment profiles for specific samples. In this case, we use the following codes:

```{r bamCoverage_plot_samples, include=TRUE, echo=TRUE, eval=TRUE}
sample.ids <- c('rep1_4HT-', 'rep1_4HT+', 'rep2_4HT-', 'rep2_4HT+')
tan::plotCoverage(coverage, peak_id = peak.id, sample_ids = sample.ids, title = toString(gr[peak.id]))
```


# Diffential analysis 

The [tan](https://github.com/duydnguyen/tan/)'s differential analysis workflow consists of two main phases: 

1. Generating empirical null distributions, 

2. Testing phase and predicting differential
regions. 

Here, we present an example of 8000 genomic regions sampled from our H3K27me3 data. We included the following inputs: (1) a set of genomic regions, and (2) their corresponding read coverages.  

```{r GR_info, include = TRUE, echo = TRUE, eval = TRUE}
files = list.files(system.file("extdata",
        package = "tanExample"),full.names = TRUE)
basename(files[2:3])
load(files[3])
gr_sitesSelect
```   

## Creating a **tanDb** object 

We first load the coverage, and construct a **tanDb** object as follows. 

```{r tanDb_construct, include = TRUE, echo = TRUE, eval = FALSE}
load(files[2])
tanDb <- new("tanDb", coverage = coverage)
```

## Sampling design

The [tan](https://github.com/duydnguyen/tan/)'s power lies in accomodating regions (or peaks)  with different lengths by using the adaptive Neyman statistics.  Its ***adaptive*** property not only allows a wide range of peak lengths, but also improve the power of detecting DE regions. However, for cases of regions with large genomic intervals, we advise using a sampling design across these intervals. This procedure mimics a Latin hypercube sampling in computer experiments or for Monte-Carlo integration. Such designs have a space-filling property which helps capture the spatial and shape structures of histone profile coverage. As a result, it improves the power of detecting DE regions. For instance, using the `createDesigns()`, we could create a grid of evenly spaced points for each region. 

```{r design, include = TRUE, echo = TRUE, eval = FALSE}
tanDb <- createDesigns(tanDb, s.size = 500, LHD = TRUE, Uniform = FALSE )
```

## Empirical null distributions

In phase 1, TAN evaluates the (within) Neyman statistics
between pairs of replicates within the same conditions. Then, it
clusters these peaks into bins based on their total counts. These bins
are simply partitions of read counts across the pre-defined genomic
regions. After that, TAN constructs the corresponding null
distributions based on the statistics available from each bin (or partition) of counts. 

To obtain this goal, we first generate total counts (or area under coverage profiles). This step is required for peak clustering in later steps. We proceed as follows: 

```{r totalCounts, include = FALSE, echo = FALSE, eval = TRUE}
load(files[4])
```

```{r totalCounts2, include = TRUE, echo = TRUE, eval = FALSE}
tanDb <- calculateTotalCounts(tanDb, nSamples = 3, bNormWidth = FALSE, 
                              bSampleMean = FALSE)
head(tanDb@Ns)
```

```{r totalCounts3, include = TRUE, echo = FALSE, eval = TRUE}
print(head(tanDb@Ns))
```

Next, we cluster peaks into bins based on their total counts obtained by the previous step. 

```{r calculateWithinSites, include = TRUE, echo = TRUE, eval = FALSE}
# quantile vector for binning
quantprobs <- seq(0, 1, 0.05) 
tanDb <- calculateWithinSites(tanDb, quantprobs = quantprobs)
```

We then calculate the variance for each grid point in our sampling design obtained from previous step. Based on the clustering, we also pool variance for sites within the same clusters. 

```{r calculateVariance, include = TRUE, echo = TRUE, eval = FALSE}
Global_lower <- 100
## pooled quantile at each genomic position: 
poolQuant <- 0.5
# number of points for moving average
movAve <- 20
tanDb <- calculateVariance(tanDb, minus_condition = TRUE, 
                           Global_lower = Global_lower, 
                           poolQuant = poolQuant, movAve = movAve )
tanDb <- calculateVariance(tanDb, minus_condition = FALSE, 
                           Global_lower = Global_lower, 
                           poolQuant = poolQuant, movAve = movAve )
```

Finally, (within) adaptive Neyman statistics for are obtained as follows:  

```{r generateWithinTan, include = TRUE, echo = TRUE, eval = FALSE}
tanDb <- generateWithinTan(tanDb, minus_condition = TRUE)
tanDb <- generateWithinTan(tanDb, minus_condition = FALSE)
```

This completes the phase 1 of our pipeline. 

## Testing phase

For testing phase, [tan](https://github.com/duydnguyen/tan/) constructs the
(between) Neyman statistics by testing replicates from different
conditions. It then maps the regions being tested to their corresponding
empirical null distributions based on regions' total read
counts. Consequently, TAN provides the _p-values_ for each testing
regions, leading to the prediction of differential regions after
multiple testing correction. The code is as follows:

```{r computePvalues, include = TRUE, echo = TRUE, eval = FALSE}
tanDb <- computePvalues(tanDb, quant = 0.5, poolQuant = poolQuant, 
                        movAve = movAve, Global_lower = Global_lower, 
                        ignore_sitesUnused = TRUE,
                        na_impute = FALSE)
```

The raw and adjusted _p-values_ could be obtained by extracting slot `tanDb@PvalList`. This completes the testing phase.

Furthermore, the quantile parameter `quant` for combined _p-values_ could be adjusted without rerunning `computePvalues.` The following function performs this task:

```{r evalPvals, include = TRUE, echo = TRUE, eval = FALSE}
pvals <- evalPvals(P = tanDb@PvalList, total = nrow(P[['pval']]), quant = 0.25, 
                   nSamples = tanDb@nSamples, BH = FALSE, na.rm = TRUE)
pvals.a <- p.adjust(pvals, method = 'BH')
```

The adjusted _p-values_ could be obtained directly by changing the parameter `BH = FALSE` to `BH = TRUE.` 

```{r evalPvals_adjusted, include = TRUE, echo = TRUE, eval = FALSE}
pvals.a <- evalPvals(P = tanDb@PvalList, total = nrow(P[['pval']]), quant = 0.25, 
                   nSamples = tanDb@nSamples, BH = TRUE, na.rm = TRUE)
```

For visualizing the results of diffentially/non-differentially enriched sites declared by our method, we could use the `plotCoverage` function as described in previous sections.

```{r viz_coverage, include = TRUE, echo = TRUE, eval = FALSE}
de_sites <- which(pvals.a <= 0.05)
tan::plotCoverage(coverage = tanDb@coverage, peak_id = de_sites[1], title = 'coverage plot of DE site')
```





